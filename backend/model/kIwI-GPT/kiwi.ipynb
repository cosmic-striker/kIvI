{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d8ab58f7-9c3d-4676-b29d-0dcf37218249",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "import pickle\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "block_size = 64\n",
    "batches = 32\n",
    "train_loop = 5000\n",
    "learning_rate = 5e-4\n",
    "train_split = 0.8\n",
    "debug_loop = 500\n",
    "embeds = 512\n",
    "heads = 4\n",
    "layers = 8\n",
    "dropout = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "246ca4f0-e78a-4a15-944c-a5a2b2f6db5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\\n', ' ', '\"', '.', '0', '1', '2', '3', '4', '5', '7', 'A', 'B', 'H', 'I', 'L', 'M', 'P', 'W', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n",
      "45\n"
     ]
    }
   ],
   "source": [
    "chars = \"\"\n",
    "with open('persion.txt', 'r', encoding='utf-8') as f:\n",
    "    text = f.read()\n",
    "    chars = sorted(set(text))\n",
    "print(chars)\n",
    "vocab_size = len(chars)\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b2deb00b-e88b-445d-9c0b-3e07665cda93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([39, 37, 23, 36,  1,  5,  1, 34, 23, 36, 37, 33, 32, 19, 37,  0,  2, 14,\n",
      "         1, 28, 39, 37, 38,  1, 20, 33, 39, 25, 26, 38,  1, 19,  1, 20, 36, 19,\n",
      "        32, 22,  1, 32, 23, 41,  1, 26, 33, 39, 37, 23,  3,  0, 14,  1, 30, 27,\n",
      "        29, 23,  1, 38, 33,  1, 22, 19, 32, 21, 23,  1, 19, 38,  1, 38, 26, 23,\n",
      "         1, 21, 30, 39, 20,  3,  0, 14,  1, 36, 39, 32,  1, 19,  1, 22, 33, 25,\n",
      "         1, 33, 20, 23, 22, 27, 23, 32, 21, 23], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "str2int = { ch:i for i,ch in enumerate(chars) }\n",
    "int2str = { i:ch for i,ch in enumerate(chars) }\n",
    "encode = lambda s: [ str2int[c] for c in s ]\n",
    "decode = lambda l: ''.join([ int2str[i] for i in l ])\n",
    "data = torch.tensor(encode(text), dtype=torch.long).to(device)\n",
    "print(data[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d35fe940-99a8-4e66-a4e0-a00d7fc72700",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs:\n",
      "tensor([[19, 40, 33,  ..., 21, 33, 31],\n",
      "        [19, 27, 37,  ..., 23,  1, 32],\n",
      "        [ 1, 27, 32,  ..., 31,  1, 19],\n",
      "        ...,\n",
      "        [37, 23, 19,  ..., 27, 37, 38],\n",
      "        [ 0, 14,  1,  ..., 23, 23,  1],\n",
      "        [ 1, 38, 33,  ...,  1, 24, 39]], device='cuda:0')\n",
      "target:\n",
      "tensor([[40, 33, 36,  ..., 33, 31, 34],\n",
      "        [27, 37, 23,  ...,  1, 32, 33],\n",
      "        [27, 32,  1,  ...,  1, 19,  1],\n",
      "        ...,\n",
      "        [23, 19,  3,  ..., 37, 38, 23],\n",
      "        [14,  1, 30,  ..., 23,  1, 26],\n",
      "        [38, 33,  1,  ..., 24, 39, 36]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "n = int(train_split*len(data))\n",
    "train = data[:n]\n",
    "valid = data[n:]\n",
    "\n",
    "def get_batch(split):\n",
    "    data = train if split=='train' else valid\n",
    "    ix = torch.randint(len(data) - block_size, (batches,))\n",
    "    # print(ix)\n",
    "    x = torch.stack([data[i:i+block_size] for i in ix])\n",
    "    y = torch.stack([data[i+1:i+block_size+1] for i in ix])\n",
    "    x, y = x.to(device), y.to(device)\n",
    "    return x, y\n",
    "\n",
    "x, y = get_batch('train')\n",
    "print('inputs:')\n",
    "print(x)\n",
    "print('target:')\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "26ed70f3-5e3e-4522-8567-7857d629c0b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Head(nn.Module):\n",
    "    def __init__(self, head_size):\n",
    "        super().__init__()\n",
    "        self.key = nn.Linear(embeds, head_size, bias=False)\n",
    "        self.query = nn.Linear(embeds, head_size, bias=False)\n",
    "        self.value = nn.Linear(embeds, head_size, bias=False)\n",
    "        self.register_buffer('tril', torch.tril(torch.ones(block_size, block_size)))\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "    def forward(self, x):\n",
    "        B, T, C = x.shape\n",
    "        k = self.key(x)\n",
    "        q = self.query(x)\n",
    "        wei = q @ k.transpose(-2, -1) * k.shape[-1]**-.5\n",
    "        wei = wei.masked_fill(self.tril[:T, :T]==0, float('-inf'))\n",
    "        wei = F.softmax(wei, dim=-1)\n",
    "        wei = self.dropout(wei)\n",
    "        v = self.value(x)\n",
    "        out = wei @ v\n",
    "        return out\n",
    "\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, num_heads, head_size):\n",
    "        super().__init__()\n",
    "        self.heads = nn.ModuleList([Head(head_size) for _ in range(num_heads)])\n",
    "        self.proj = nn.Linear(head_size * num_heads, embeds)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "    def forward(self, x):\n",
    "        out = torch.cat([h(x) for h in self.heads], dim=-1)\n",
    "        out = self.dropout(self.proj(out))\n",
    "        return out\n",
    "\n",
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, embed):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(embeds, 4*embeds),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(4*embeds, embeds),\n",
    "            nn.Dropout(dropout),\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "class Block(nn.Module):\n",
    "    def __init__(self, embeds, heads):\n",
    "        super().__init__()\n",
    "        head_size = embeds // heads\n",
    "        self.sa = MultiHeadAttention(heads, head_size)\n",
    "        self.ffwd = FeedForward(embeds)\n",
    "        self.ln1 = nn.LayerNorm(embeds)\n",
    "        self.ln2 = nn.LayerNorm(embeds)\n",
    "    def forward(self, x):\n",
    "        y = self.sa(x)\n",
    "        x = self.ln1(x + y)\n",
    "        y = self.ffwd(x)\n",
    "        x = self.ln2(x + y)\n",
    "        return x\n",
    "\n",
    "class Kiwi(nn.Module):\n",
    "    def __init__(self, vocab_size):\n",
    "        super().__init__()\n",
    "        self.token_embedding = nn.Embedding(vocab_size, embeds)\n",
    "        self.position_embedding = nn.Embedding(block_size, embeds)\n",
    "        self.blocks = nn.Sequential(*[Block(embeds, heads=heads) for _ in range(layers)])\n",
    "        self.final_norm = nn.LayerNorm(embeds)\n",
    "        self.head = nn.Linear(embeds, vocab_size)\n",
    "        self.apply(self._init_weights)\n",
    "\n",
    "    def _init_weights(self, module):\n",
    "        if isinstance(module, nn.Linear):\n",
    "            nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
    "            if module.bias is not None:\n",
    "                nn.init.zeros_(module.bias)\n",
    "        elif isinstance(module, nn.Embedding):\n",
    "            nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
    "\n",
    "    def forward(self, index, targets=None):\n",
    "        B, T = index.shape\n",
    "\n",
    "        tok = self.token_embedding(index)\n",
    "        pos = self.position_embedding(torch.arange(T, device=device))\n",
    "        x = tok + pos\n",
    "        x = self.blocks(x)\n",
    "        x = self.final_norm(x)\n",
    "        logits = self.head(x)\n",
    "        if targets is None:\n",
    "            loss = None\n",
    "        else:\n",
    "            B, T, C = logits.shape\n",
    "            logits = logits.view(B*T, C)\n",
    "            targets = targets.view(B*T)\n",
    "            loss = F.cross_entropy(logits, targets)\n",
    "        return logits, loss\n",
    "        \n",
    "    def generate(self, index, max_new_tokens):\n",
    "        for iter in range(max_new_tokens):\n",
    "            index_crop = index[:, -block_size:]\n",
    "            logits, loss = self.forward(index_crop)\n",
    "            logits = logits[:, -1, :]\n",
    "            probs = F.softmax(logits, dim=-1)\n",
    "            index_next = torch.multinomial(probs, num_samples=1)\n",
    "            index = torch.cat((index, index_next), dim=1)\n",
    "            print(f\"\\r<{'*' * int(10 * iter/max_new_tokens)}{' ' * (10 - int(10*iter/max_new_tokens))}>\", end='', flush=False)\n",
    "        print(\"\\r<**********>\")\n",
    "        return index\n",
    "\n",
    "m = Kiwi(vocab_size)\n",
    "model = Kiwi(vocab_size).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "345394da-ace6-4a22-ab85-ee8f29b7f61a",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def estimate_loss(model):\n",
    "    out = {}\n",
    "    model.eval()\n",
    "    for split in ['train', 'val']:\n",
    "        losses = torch.zeros(debug_loop)\n",
    "        for k in range(debug_loop):\n",
    "            X, Y = get_batch(split)\n",
    "            logits, loss = model(X, Y)\n",
    "            losses[k] = loss.item()\n",
    "        out[split] = losses.mean()\n",
    "    model.train()\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fd9e8cc8-75ec-4fd8-913a-ccc19b2c9ee2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 0, train loss: 3.918626, valid loss: 3.920266\n",
      "step: 500, train loss: 0.612665, valid loss: 0.636477\n",
      "step: 1000, train loss: 0.351458, valid loss: 0.367271\n",
      "step: 1500, train loss: 0.309351, valid loss: 0.331282\n",
      "step: 2000, train loss: 0.285331, valid loss: 0.308199\n",
      "step: 2500, train loss: 0.262747, valid loss: 0.295625\n",
      "step: 3000, train loss: 0.247159, valid loss: 0.277548\n",
      "step: 3500, train loss: 0.241433, valid loss: 0.273690\n",
      "step: 4000, train loss: 0.230591, valid loss: 0.264746\n",
      "step: 4500, train loss: 0.226760, valid loss: 0.263119\n",
      "0.2556634545326233\n",
      "CPU times: total: 5min 15s\n",
      "Wall time: 14min 57s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "optim = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
    "for iter in range(train_loop):\n",
    "    if iter % debug_loop == 0:\n",
    "        losses = estimate_loss(model)\n",
    "        print(f'step: {iter}, train loss: {losses['train']:.6f}, valid loss: {losses['val']:.6f}')\n",
    "\n",
    "    xb, yb = get_batch('train')\n",
    "    logits, loss = model.forward(xb, yb)\n",
    "    optim.zero_grad(set_to_none=True)\n",
    "    loss.backward()\n",
    "    optim.step()\n",
    "print(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3a4ce780-e5a2-4570-9a94-4ccc71e45430",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<**********>\n",
      "\n",
      "I enjoy exercising for long hours.\n",
      "I spend my free time reading plast yor ago.\"\n",
      "\"I love watching sports on tv.\n",
      "I like to paint in my spare time.\n",
      "I live in ohio.\"\n",
      "\"I have a music.\n",
      "I am a ser 22 year old girl.\n",
      "I am taking cing civil war antiques.\n",
      "I have 3 sisters.\"\n",
      "\"I love to meut new people.\n",
      "My favorite singer is time of missississippi.\n",
      "I am 34 years old trans boy.\"\n",
      "\"I love dogs but hate cats.\n",
      "I love to play on second life.\n",
      "I am a huge ed sheeran fan.\n",
      "I am looking forward to retiring in five years.\n",
      "I like ot play racquetball.\n",
      "I love tryink ansas.\n",
      "I love to build things with my hands.\n",
      "I have dinner with my family and then go out play with friends.\"\n",
      "\"I love to surf and skate.\n",
      "I have two cats.\n",
      "I like children in that are in their kindergarten.\"\n",
      "\"I am colorblind.\"\n",
      "\"My best friend is a robot.\n",
      "I am color blind and live with my little sister.\"\n",
      "\"I have a husband works nights of america.\n",
      "I am a student.\n",
      "I have a dog named maxed max.\n",
      "I am serving in south korea.\n",
      "I am a violent personal skater.\n",
      "I \n",
      "CPU times: total: 15.5 s\n",
      "Wall time: 22.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "ctx = torch.zeros((1, 1), dtype=torch.long, device=device)\n",
    "generated = decode(model.generate(ctx, max_new_tokens=1000)[0].tolist())\n",
    "print(generated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cb483c83-1e49-4486-8ee2-91a177b77118",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'K'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m prompt \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mHi. We are the developers of Kiwi\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m----> 2\u001b[0m context \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(\u001b[43mencode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m)\u001b[49m, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mlong, device\u001b[38;5;241m=\u001b[39mdevice)\n\u001b[0;32m      3\u001b[0m generated_chars \u001b[38;5;241m=\u001b[39m decode(model\u001b[38;5;241m.\u001b[39mgenerate(context\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m), max_new_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m500\u001b[39m)[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mtolist())\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(generated_chars)\n",
      "Cell \u001b[1;32mIn[3], line 3\u001b[0m, in \u001b[0;36m<lambda>\u001b[1;34m(s)\u001b[0m\n\u001b[0;32m      1\u001b[0m str2int \u001b[38;5;241m=\u001b[39m { ch:i \u001b[38;5;28;01mfor\u001b[39;00m i,ch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(chars) }\n\u001b[0;32m      2\u001b[0m int2str \u001b[38;5;241m=\u001b[39m { i:ch \u001b[38;5;28;01mfor\u001b[39;00m i,ch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(chars) }\n\u001b[1;32m----> 3\u001b[0m encode \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m s: [ \u001b[43mstr2int\u001b[49m\u001b[43m[\u001b[49m\u001b[43mc\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m s ]\n\u001b[0;32m      4\u001b[0m decode \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m l: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin([ int2str[i] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m l ])\n\u001b[0;32m      5\u001b[0m data \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(encode(text), dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mlong)\u001b[38;5;241m.\u001b[39mto(device)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'K'"
     ]
    }
   ],
   "source": [
    "prompt = 'Hi. We are the developers of Kiwi'\n",
    "context = torch.tensor(encode(prompt), dtype=torch.long, device=device)\n",
    "generated_chars = decode(model.generate(context.unsqueeze(0), max_new_tokens=500)[0].tolist())\n",
    "print(generated_chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1fc2bf8-0830-4d5a-9c53-7bfd2fab9260",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "import speech_recognition as sr\n",
    "import pyttsx3\n",
    "\n",
    "gender = 1\n",
    "\n",
    "listener = sr.Recognizer()\n",
    "engine = pyttsx3.init('sapi5')\n",
    "voices = engine.getProperty(\"voices\")\n",
    "engine.setProperty('voice',voices[gender].id)\n",
    "\n",
    "def talk(audio):\n",
    "    engine.say(audio)\n",
    "    engine.runAndWait()\n",
    "\n",
    "talk(generated)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aafb13d5-c612-421d-af51-c24579480c63",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
